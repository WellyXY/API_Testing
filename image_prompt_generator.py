from vertexai.generative_models import GenerativeModel, Part, SafetySetting
import vertexai
import os
from PIL import Image
import io
import random

# ========== è®¤è¯é…ç½® ==========
import json
import tempfile

# æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ—§è®¤è¯
os.environ.pop("GOOGLE_APPLICATION_CREDENTIALS", None)

# ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > æœ¬åœ°æ–‡ä»¶ > é›†ç¾¤æ–‡ä»¶
LOCAL_CREDENTIALS = os.path.join(os.path.dirname(__file__), "vertex-ai.json")
CLUSTER_CREDENTIALS = "/mnt/nfs/chenlin/dataproc/vertex-ai.json"

# 1. å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å– JSON å†…å®¹ï¼ˆVercel ç­‰çº¿ä¸Šç¯å¢ƒï¼‰
vertex_ai_json = os.getenv("VERTEX_AI_JSON")
if vertex_ai_json:
    try:
        # éªŒè¯ JSON æ ¼å¼
        credentials_data = json.loads(vertex_ai_json)
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False)
        json.dump(credentials_data, temp_file)
        temp_file.close()
        VERTEX_AI_CREDENTIALS = temp_file.name
        print(f"âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡è®¤è¯ (VERTEX_AI_JSON)", flush=True)
    except json.JSONDecodeError as e:
        print(f"âš ï¸ VERTEX_AI_JSON æ ¼å¼é”™è¯¯: {e}", flush=True)
        vertex_ai_json = None

# 2. å°è¯•æœ¬åœ°æ–‡ä»¶
if not vertex_ai_json and os.path.exists(LOCAL_CREDENTIALS):
    VERTEX_AI_CREDENTIALS = LOCAL_CREDENTIALS
    print(f"âœ… ä½¿ç”¨æœ¬åœ°è®¤è¯æ–‡ä»¶: {LOCAL_CREDENTIALS}", flush=True)
# 3. å°è¯•é›†ç¾¤æ–‡ä»¶
elif not vertex_ai_json and os.path.exists(CLUSTER_CREDENTIALS):
    VERTEX_AI_CREDENTIALS = CLUSTER_CREDENTIALS
    print(f"âœ… ä½¿ç”¨é›†ç¾¤è®¤è¯æ–‡ä»¶: {CLUSTER_CREDENTIALS}", flush=True)
# 4. éƒ½ä¸å­˜åœ¨åˆ™æŠ¥é”™
elif not vertex_ai_json:
    raise FileNotFoundError(
        f"æ‰¾ä¸åˆ°è®¤è¯æ–‡ä»¶ï¼è¯·ç¡®ä¿ä»¥ä¸‹ä»»ä¸€æ¡ä»¶æ»¡è¶³:\n"
        f"  - ç¯å¢ƒå˜é‡ VERTEX_AI_JSON åŒ…å«è®¤è¯ JSON\n"
        f"  - æœ¬åœ°æ–‡ä»¶: {LOCAL_CREDENTIALS}\n"
        f"  - é›†ç¾¤æ–‡ä»¶: {CLUSTER_CREDENTIALS}"
    )

os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = VERTEX_AI_CREDENTIALS


def clean_gemini_output(s: str) -> str:
    """æ¸…ç† Gemini è¾“å‡ºæ–‡æœ¬"""
    result = s.strip()
    result = result.replace('\u00a0', ' ')
    result = result.replace('\xa0', ' ')
    result = result.replace('\u2013', '-')
    result = result.replace('\u2014', '-')
    result = result.replace('\u2019', "'")
    result = result.replace('\u201c', '"')
    result = result.replace('\u201d', '"')
    result = result.replace('**', '').strip()
    while '  ' in result:
        result = result.replace('  ', ' ')
    return result


def get_gemini_response(prompt, image=None, model="gemini-2.5-flash"):
    """è°ƒç”¨ Gemini API è·å–å“åº”"""
    vertexai.init(
        project="quick-formula-414701", 
        location=random.choice(["europe-west4", "europe-west1", "europe-southwest1"])
    )
    
    safety_settings = [
        SafetySetting(
            category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold=SafetySetting.HarmBlockThreshold.BLOCK_NONE,
        ),
        SafetySetting(
            category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=SafetySetting.HarmBlockThreshold.BLOCK_NONE,
        ),
        SafetySetting(
            category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold=SafetySetting.HarmBlockThreshold.BLOCK_NONE,
        ),
        SafetySetting(
            category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=SafetySetting.HarmBlockThreshold.BLOCK_NONE,
        ),
    ]
    
    gen_config = {
        "max_output_tokens": 4096,
        "temperature": 0.7,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´å¤šæ ·åŒ–çš„ç»“æœ
        "response_mime_type": "text/plain",
    }
    
    try:
        gemini = GenerativeModel(model)
        input_list = []

        if image is not None:
            # è°ƒæ•´å›¾ç‰‡å¤§å°
            image = image.convert('RGB')
            image.thumbnail((640, 640))
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='JPEG')
            img_bytes = img_byte_arr.getvalue()
            image_part = Part.from_data(data=img_bytes, mime_type="image/jpeg")
            input_list.append(image_part)
        
        input_list.append(prompt)
        
        response = gemini.generate_content(
            input_list, 
            safety_settings=safety_settings, 
            generation_config=gen_config
        )
            
        return response.text
    except Exception as e:
        print(f"Error: {e}", flush=True)
        return '[gemini generation failed]'


# Generate 3 variant prompts (concise constraints, no samples/lists)
MULTI_PROMPT_TEMPLATE = """
You are an expert image prompt writer. You will receive ONE reference image.

Objective:
- Produce EXACTLY 3 prompts in Chinese; EACH prompt must contain TWO sentences:
  1) Base visual description of the reference image (concise but detailed, â‰ˆ40â€“80 Chinese characters)
  2) Minimal modification instruction (ä¿æŒæ„å›¾ä¸å˜ + å˜æ›´åŠ¨ä½œ/æ‰‹éƒ¨/è¡¨æƒ…/é•œå¤´ï¼›ç»“å°¾â€œåŒæ—¶ç¡®ä¿æ„å›¾ä¸€è‡´â€)
- Preserve base composition, subject pose, scene and background.
- Make only minimal, plausible changes: hand placement, subtle body posture, facial expression, or camera angle.
- At least ONE prompt MUST change the camera angle (but DO NOT raise the camera), and at least ONE prompt MUST add a clear hand action.

Variation and richness:
- Start EACH prompt by describing the reference image in detail (in Chinese):
  - Character's physical features (hair color, hair length, body state, skin tone)
  - Current pose and position (sitting/standing/riding/lying, etc.)
  - Facial expression and gaze direction
  - Body contact and interaction with any other person
  - Lighting, atmosphere, and mood
- Then add ONE minimal modification sentence (hand/pose/expression/camera) as instruction.
- Prefer dynamic hand actions when plausible and visible (e.g., æŠ“èƒ¸ã€æ‹¨å¤´å‘ã€æŠšæ‘¸å¤§è…¿ã€å°†æ‰‹æ”¾åœ¨ç”·å­èƒ¸è†›ï¼›æ¡ä½é˜´èŒä»…åœ¨å£äº¤ç­‰ç‰©ç†å¯è¡Œæƒ…å¢ƒä¸‹)ã€‚
- Keep each change minimal but noticeable; avoid introducing new objects or people.
// Camera change constraints (hard rule):
// - DO NOT move the camera upward/top-down/high-angle (ç¦æ­¢ä¿¯è§†/ç•¥å¾®ä¿¯è§†/from above)
// - Prefer side view, eye-level, or slightly lower angle (ä¾§é¢/å¹³è§†/ç•¥å¾®ä»°è§†) when changing camera

Physical feasibility:
- First infer the sexual position/activity depicted (e.g., cowgirl, blow job, missionary, doggy).
- Only propose actions that are physically possible for that position.
- If an element is not visible in the image, do not mention it.
- Keep explicitness consistent with the image; do not censor; do not add technical specs.

Style and output format:
- EACH prompt MUST contain TWO Chinese sentences:
  1) Base visual description of the current image (40â€“80 chars)
  2) Modification instruction in the structure: ã€Œä¿æŒç”»é¢ä¸­äººç‰©çš„åŠ¨ä½œä»¥åŠèƒŒæ™¯ä¸å˜ï¼Œâ€¦â€¦ã€‚åŒæ—¶ç¡®ä¿æ„å›¾ä¸€è‡´ã€
- Output ONLY the following, with no explanations and no examples:

[PROMPT 1]
<Chinese base description sentence>
<Chinese modification instruction sentence>

[PROMPT 2]
<Chinese base description sentence>
<Chinese modification instruction sentence>

[PROMPT 3]
<Chinese base description sentence>
<Chinese modification instruction sentence>

Optional user hint (context only, do not copy): {user_prompt}
"""


def generate_variant_prompts(user_prompt: str, image: Image.Image, max_retries: int = 3):
    """
    åŸºäºç”¨æˆ· prompt å’Œå‚è€ƒå›¾ç‰‡ï¼Œç”Ÿæˆ 3 ä¸ªä¸åŒè§†è§’çš„å›¾ç‰‡ç”Ÿæˆ prompt
    
    Args:
        user_prompt: ç”¨æˆ·çš„åŸå§‹æè¿°
        image: å‚è€ƒå›¾ç‰‡ï¼ˆPIL Image å¯¹è±¡ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        list: åŒ…å« 3 ä¸ª prompt çš„åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    """
    
    def is_failure(text):
        """æ£€æŸ¥æ˜¯å¦ç”Ÿæˆå¤±è´¥"""
        return (
            'generation failed]' in text or 
            "i'm sorry" in text.lower() or 
            "sorry i can't" in text.lower() or
            "i cannot" in text.lower()
        )
    
    def parse_prompts(text):
        """ä» Gemini è¾“å‡ºä¸­è§£æå‡º 3 ä¸ª promptï¼ˆæ›´å¼ºå¥ï¼‰"""
        raw = (text or '').strip()
        if not raw:
            return []

        def normalize_and_pack(lines):
            # è§„æ•´åŒ–ï¼šå»å¼•å·ã€åˆå¹¶â€œåŒæ—¶ç¡®ä¿æ„å›¾ä¸€è‡´â€å­¤è¡Œã€è¡¥å¥å°¾
            quote_chars = 'ã€Œã€ã€ã€â€œâ€"\''
            suffix = 'åŒæ—¶ç¡®ä¿æ„å›¾ä¸€è‡´'
            result = []
            for token in lines:
                t = (token or '').strip()
                if not t:
                    continue
                # å»é¦–å°¾å¼•å·
                t = t.strip(quote_chars).strip()
                if not t:
                    continue
                # è‹¥æ˜¯å­¤ç«‹çš„ç»“å°¾æç¤ºï¼Œæ‹¼åˆ°ä¸Šä¸€å¥
                if t == suffix or t.startswith(suffix):
                    if result and suffix not in result[-1]:
                        result[-1] = result[-1].rstrip('ã€‚').rstrip('.') + 'ã€‚' + suffix
                    continue
                # ç¼ºå°‘ç»“å°¾åˆ™è¡¥é½
                if suffix not in t:
                    t = t.rstrip('ã€‚').rstrip('.') + 'ã€‚' + suffix
                result.append(t)
            # åªå–å‰ä¸‰æ¡
            return result[:3]

        # 0) é¦–é¸ï¼šæŒ‰ [PROMPT x] è§£æå…©å¥å¼ï¼ˆåŸºç¤æè¿° + ä¿®æ”¹æŒ‡ä»¤ï¼‰
        lines = [l.strip() for l in raw.splitlines()]
        merged = []
        for i in range(1, 4):
            try:
                # æ‰¾åˆ° [PROMPT i]
                idx = next(k for k, l in enumerate(lines) if l.upper().startswith(f'[PROMPT {i}]'))
                # å–å¾ŒçºŒå…©å€‹éç©ºè¡Œ
                base_line = ''
                instr_line = ''
                p = idx + 1
                while p < len(lines) and not base_line:
                    if lines[p] and not lines[p].upper().startswith('[PROMPT'):
                        base_line = lines[p]
                    p += 1
                while p < len(lines) and not instr_line:
                    if lines[p] and not lines[p].upper().startswith('[PROMPT'):
                        instr_line = lines[p]
                    p += 1
                if base_line and instr_line:
                    # æ¸…ç†ä¸¦åˆä½µç‚ºåŒä¸€æ¢ promptï¼ˆå…©å¥ï¼‰
                    pair = clean_gemini_output(base_line) + ' ' + clean_gemini_output(instr_line)
                    merged.append(pair)
            except StopIteration:
                break
        if len(merged) == 3:
            return merged

        # 0.1) é€€åŒ–ï¼šè‹¥æ²’æœ‰ [PROMPT x]ï¼Œå˜—è©¦æ•ç²æˆå°çš„å…©è¡Œï¼ˆéç©ºé€£çºŒå…©è¡Œç‚ºä¸€çµ„ï¼‰ï¼Œå–å‰ä¸‰çµ„
        pairs = []
        buff = []
        for l in lines:
            if not l:
                continue
            if l.upper().startswith('[PROMPT'):
                continue
            buff.append(l)
            if len(buff) == 2:
                pairs.append(clean_gemini_output(buff[0]) + ' ' + clean_gemini_output(buff[1]))
                buff = []
        if len(pairs) >= 3:
            return pairs[:3]

        # 0.2) ä»ä¸è¶³ï¼šæŠ“å–â€œä¿æŒâ€¦åŒæ—¶ç¡®ä¿æ„å›¾ä¸€è‡´â€çš„æŒ‡ä»¤å¥ï¼Œä½œç‚ºæœ€å°é€€åŒ–æ–¹æ¡ˆ
        import re
        pattern = r'ä¿æŒ[\s\S]*?åŒæ—¶ç¡®ä¿æ„å›¾ä¸€è‡´'
        groups = re.findall(pattern, raw)
        if len(groups) >= 3:
            return normalize_and_pack(groups[:3])

        # 1) ä¼˜å…ˆè§£æ [PROMPT x] ç»“æ„
        parts = raw.split('[PROMPT ')
        tmp = []
        for i in range(1, 4):
            for part in parts:
                s = part.strip()
                if s.startswith(f'{i}]'):
                    content = s.split(']', 1)[1].strip()
                    if '[PROMPT' in content:
                        content = content.split('[PROMPT')[0].strip()
                    if content:
                        # å»é™¤æ¢è¡Œï¼Œé¿å…è¢«é”™è¯¯æ‹†åˆ†
                        tmp.append(clean_gemini_output(content.replace('\n', ' ')))
                    break
        if len(tmp) == 3:
            return normalize_and_pack(tmp)

        # 2) è§£æä»¥æ•°å­—ç¼–å·çš„ä¸‰è¡Œï¼ˆ1. / 2. / 3.ï¼‰
        lines = [l.strip() for l in raw.splitlines() if l.strip()]
        tmp = []
        for line in lines:
            if line[:2].isdigit() or (len(line) > 2 and line[0].isdigit() and line[1] in ['.', 'ã€', ')']):
                # å»æ‰å‰ç¼€ç¼–å·
                if '. ' in line:
                    line = line.split('. ', 1)[1].strip()
                elif 'ã€' in line:
                    line = line.split('ã€', 1)[1].strip()
                elif ') ' in line:
                    line = line.split(') ', 1)[1].strip()
                tmp.append(clean_gemini_output(line))
        if len(tmp) >= 3:
            return normalize_and_pack(tmp)

        # 3) å¦‚æœåªæœ‰çº¯æ–‡æœ¬ï¼Œå°è¯•æŒ‰ä¸­æ–‡å¥å·/æ¢è¡Œåˆ‡åˆ†ï¼Œå–å‰ä¸‰å¥
        import re
        sentences = re.split(r'[\nã€‚]+', raw)
        sentences = [s.strip() for s in sentences if s.strip()]
        if len(sentences) >= 3:
            return normalize_and_pack(sentences[:3])

        return []
    
    # é‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        print(f"å°è¯•ç”Ÿæˆ prompts (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)...", flush=True)
        
        response = get_gemini_response(
            MULTI_PROMPT_TEMPLATE.format(user_prompt=user_prompt),
            image=image,
            model="gemini-2.5-flash"
        )
        
        if is_failure(response):
            print(f"ç”Ÿæˆå¤±è´¥ï¼Œé‡è¯•ä¸­...", flush=True)
            continue
        
        # è§£æ prompts
        prompts = parse_prompts(response)
        
        if len(prompts) == 3:
            print(f"âœ… æˆåŠŸç”Ÿæˆ 3 ä¸ª prompts!", flush=True)
            return prompts
        else:
            print(f"âš ï¸ è§£æå‡º {len(prompts)} ä¸ª promptsï¼ŒæœŸæœ› 3 ä¸ªï¼Œé‡è¯•ä¸­...", flush=True)
            print(f"åŸå§‹å“åº”:\n{response}\n", flush=True)
    
    print(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç”Ÿæˆå¤±è´¥", flush=True)
    return []


def generate_variant_prompts_simple(user_prompt: str, image: Image.Image):
    """
    ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºç”¨æˆ· prompt å’Œå‚è€ƒå›¾ç‰‡ï¼Œç”Ÿæˆ 3 ä¸ªä¸åŒè§†è§’çš„ prompt
    ç›´æ¥è¿”å› 3 ä¸ª promptï¼Œä¸è¿›è¡Œå¤æ‚çš„è§£æ
    """
    
    simple_template = """
Analyze this image and the user's description: "{user_prompt}"

Generate 3 different camera angle variations for image generation. Output ONLY the 3 prompts, numbered 1, 2, 3, with NO explanations.

1. [First camera angle variation]
2. [Second camera angle variation]  
3. [Third camera angle variation]
"""
    
    response = get_gemini_response(
        simple_template.format(user_prompt=user_prompt),
        image=image
    )
    
    # ç®€å•è§£æï¼šæŒ‰è¡Œåˆ†å‰²ï¼Œæ‰¾åˆ°ä»¥æ•°å­—å¼€å¤´çš„è¡Œ
    lines = response.strip().split('\n')
    prompts = []
    
    for line in lines:
        line = line.strip()
        # åŒ¹é… "1. ", "2. ", "3. " å¼€å¤´çš„è¡Œ
        if line and line[0].isdigit() and '. ' in line:
            # ç§»é™¤æ•°å­—å’Œç‚¹å·
            prompt = line.split('. ', 1)[1].strip()
            prompts.append(clean_gemini_output(prompt))
    
    return prompts[:3] if prompts else []


# ========== Video Prompt Generation ==========

VIDEO_PROMPT_TEMPLATE = """
You are an expert video generation prompt writer. You are given an image prompt (describing a static scene) and an original video prompt (describing motion and action). Your task is to combine these two to create an enhanced video generation prompt.

Image Prompt (Visual Details):
{image_prompt}

Original Video Prompt (Motion/Action):
{video_prompt}

INSTRUCTIONS:

1. Start with the visual details from the Image Prompt:
   - Character appearance (hair, skin, body, face details)
   - Position and pose
   - Explicit anatomical details
   - Lighting and atmosphere
   - Facial expression and hand positions

2. Add motion/action from the Original Video Prompt:
   - Body movement (hips thrusting, body rocking, bouncing, etc.)
   - Intensity of motion (rhythmic, forceful, gentle, etc.)
   - Direction and speed of movement
   - Dynamic elements

3. Create a cohesive video prompt that:
   - Describes WHAT the scene looks like (from image prompt)
   - Describes HOW things move (from video prompt)
   - Maintains all explicit content - do NOT censor
   - Is 80-120 words in length
   - Uses natural, descriptive language
   - Does NOT include technical specs like "camera movement", "shot type", "4K", etc.

4. Output Format:
   - Start directly with the description
   - Single paragraph, no line breaks
   - All in ENGLISH
   - No explanations or meta-text

Example structure:
"[Visual details: character, pose, anatomy, lighting, expression] + [Motion: how the body moves, rhythm, intensity] + [Overall dynamic atmosphere]"

Generate the enhanced video prompt below:
"""


def generate_video_prompt(image_prompt: str, video_prompt: str, max_retries: int = 3) -> str:
    """
    åŸºäºå›¾ç‰‡ prompt å’ŒåŸå§‹è§†é¢‘ promptï¼Œç”Ÿæˆå¢å¼ºçš„è§†é¢‘ç”Ÿæˆ prompt
    
    Args:
        image_prompt: å›¾ç‰‡æè¿° promptï¼ˆåŒ…å«è§†è§‰ç»†èŠ‚ï¼‰
        video_prompt: åŸå§‹è§†é¢‘ promptï¼ˆåŒ…å«åŠ¨ä½œæè¿°ï¼Œå¯èƒ½åŒ…å« flagsï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        str: å¢å¼ºåçš„è§†é¢‘ç”Ÿæˆ promptï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    
    # æå– flagsï¼ˆå¦‚ --blow_job, --cowgirl ç­‰ï¼‰
    flags = []
    video_prompt_clean = video_prompt
    
    # æŸ¥æ‰¾æ‰€æœ‰ --flag æ ¼å¼çš„æ ‡è®°
    import re
    flag_pattern = r'\s+(--\w+)'
    found_flags = re.findall(flag_pattern, video_prompt)
    
    if found_flags:
        flags = found_flags
        # ç§»é™¤ flagsï¼Œåªä¿ç•™æè¿°éƒ¨åˆ†ç”¨äº Gemini å¤„ç†
        video_prompt_clean = re.sub(flag_pattern, '', video_prompt).strip()
        print(f"ğŸ·ï¸  æ£€æµ‹åˆ° flags: {', '.join(flags)}", flush=True)
    
    for attempt in range(max_retries):
        print(f"ğŸ¬ å°è¯•ç”Ÿæˆè§†é¢‘ prompt (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)...", flush=True)
        
        try:
            response = get_gemini_response(
                VIDEO_PROMPT_TEMPLATE.format(
                    image_prompt=image_prompt,
                    video_prompt=video_prompt_clean  # ä½¿ç”¨æ¸…ç†åçš„ prompt
                ),
                image=None,  # ä¸éœ€è¦å›¾ç‰‡ï¼Œåªéœ€è¦æ–‡æœ¬
                model="gemini-2.5-flash"
            )
            
            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆå¤±è´¥
            if '[gemini generation failed]' in response or \
               "i'm sorry" in response.lower() or \
               "i cannot" in response.lower():
                print(f"âš ï¸ Gemini è¿”å›å¤±è´¥æ¶ˆæ¯ï¼Œé‡è¯•ä¸­...", flush=True)
                continue
            
            # æ¸…ç†è¾“å‡º
            cleaned = clean_gemini_output(response).strip()
            
            # å¦‚æœæœ‰ flagsï¼Œåœ¨ç»“å°¾æ·»åŠ 
            if flags and cleaned:
                cleaned = cleaned + ' ' + ' '.join(flags)
                print(f"âœ… å·²æ·»åŠ  flags: {' '.join(flags)}", flush=True)
            
            # éªŒè¯è¾“å‡ºä¸ä¸ºç©ºä¸”é•¿åº¦åˆç†
            if cleaned and len(cleaned) > 50:
                print(f"âœ… æˆåŠŸç”Ÿæˆè§†é¢‘ prompt! (é•¿åº¦: {len(cleaned)} å­—ç¬¦)", flush=True)
                return cleaned
            else:
                print(f"âš ï¸ ç”Ÿæˆçš„ prompt å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œé‡è¯•ä¸­...", flush=True)
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè§†é¢‘ prompt æ—¶å‡ºé”™: {e}", flush=True)
            import traceback
            traceback.print_exc()
    
    print(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè§†é¢‘ prompt ç”Ÿæˆå¤±è´¥", flush=True)
    return ""


def generate_video_prompts_for_images(image_prompts: list[str], video_prompt: str, parallel: bool = True) -> list[str]:
    """
    ä¸ºå¤šä¸ªå›¾ç‰‡ prompts æ‰¹é‡ç”Ÿæˆå¯¹åº”çš„è§†é¢‘ prompts
    
    Args:
        image_prompts: å›¾ç‰‡ prompt åˆ—è¡¨ï¼ˆé€šå¸¸æ˜¯ 3 ä¸ªå˜ä½“ï¼‰
        video_prompt: åŸå§‹è§†é¢‘ prompt
        parallel: æ˜¯å¦å¹¶è¡Œç”Ÿæˆï¼ˆé»˜è®¤ Trueï¼‰
    
    Returns:
        list[str]: å¯¹åº”çš„è§†é¢‘ prompt åˆ—è¡¨
    """
    if not parallel:
        # ä¸²è¡Œæ¨¡å¼ï¼ˆæ—§æ–¹å¼ï¼‰
        video_prompts = []
        for i, img_prompt in enumerate(image_prompts, 1):
            print(f"\n{'='*70}", flush=True)
            print(f"ğŸ“¸ å¤„ç†å›¾ç‰‡ Prompt {i}/{len(image_prompts)}", flush=True)
            print(f"{'='*70}", flush=True)
            
            video_p = generate_video_prompt(img_prompt, video_prompt)
            
            if video_p:
                video_prompts.append(video_p)
                print(f"\nâœ… Video Prompt {i} ç”ŸæˆæˆåŠŸ\n", flush=True)
            else:
                video_prompts.append("")
                print(f"\nâŒ Video Prompt {i} ç”Ÿæˆå¤±è´¥\n", flush=True)
        
        return video_prompts
    
    # å¹¶è¡Œæ¨¡å¼
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    print(f"\nğŸš€ å¹¶è¡Œç”Ÿæˆ {len(image_prompts)} ä¸ªè§†é¢‘ prompts...", flush=True)
    
    video_prompts = [None] * len(image_prompts)
    
    def generate_with_index(index, img_prompt):
        """å¸¦ç´¢å¼•çš„ç”Ÿæˆå‡½æ•°"""
        print(f"ğŸ“¸ å¼€å§‹ç”Ÿæˆ Video Prompt {index + 1}...", flush=True)
        result = generate_video_prompt(img_prompt, video_prompt)
        if result:
            print(f"âœ… Video Prompt {index + 1} å®Œæˆ", flush=True)
        else:
            print(f"âŒ Video Prompt {index + 1} å¤±è´¥", flush=True)
        return index, result
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œç”Ÿæˆ
    with ThreadPoolExecutor(max_workers=len(image_prompts)) as executor:
        futures = {
            executor.submit(generate_with_index, i, img_prompt): i 
            for i, img_prompt in enumerate(image_prompts)
        }
        
        for future in as_completed(futures):
            index, result = future.result()
            video_prompts[index] = result if result else ""
    
    print(f"\nâœ… å¹¶è¡Œç”Ÿæˆå®Œæˆï¼", flush=True)
    return video_prompts


# ä¸»å‡½æ•°ç¤ºä¾‹
if __name__ == '__main__':
    # ç¤ºä¾‹ä½¿ç”¨
    user_prompt = "å¥³å­é›™æ‰‹æŠ“ä½è‡ªå·±çš„å¥¶å­"
    image_path = '/mnt/nfs/chenlin/model_2.0_lora/benchmarks/pika-sharing/images/example.png'
    
    # å¦‚æœå›¾ç‰‡è·¯å¾„å­˜åœ¨
    if os.path.exists(image_path):
        image = Image.open(image_path)
        
        print("="*60)
        print("åŸå§‹ Prompt:", user_prompt)
        print("="*60)
        
        # ç”Ÿæˆ 3 ä¸ªå˜ä½“ prompts
        variant_prompts = generate_variant_prompts(user_prompt, image)
        
        if variant_prompts:
            print("\nç”Ÿæˆçš„ 3 ä¸ªå˜ä½“ Prompts:\n")
            for i, prompt in enumerate(variant_prompts, 1):
                print(f"{i}. {prompt}\n")
        else:
            print("âŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
    else:
        print(f"å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨: {image_path}")
        print("\n" + "="*60)
        print("ğŸ“š ä½¿ç”¨æ–¹æ³•")
        print("="*60)
        print("""
1. åœ¨ Python è„šæœ¬ä¸­ä½¿ç”¨:
   
   from image_prompt_generator import generate_variant_prompts
   from PIL import Image
   
   image = Image.open('your_image.jpg')
   prompts = generate_variant_prompts('ä½ çš„æè¿°', image)
   
   for i, prompt in enumerate(prompts, 1):
       print(f"Prompt {i}: {prompt}")

2. åœ¨é›†ç¾¤ä¸Šè¿è¡Œ:
   
   # SSH ç™»å½•é›†ç¾¤
   ssh -i cluster_id_welly welly@142.202.71.32
   
   # è¿è¡Œè„šæœ¬
   cd /mnt/nfs/your_workspace
   python3 image_prompt_generator.py

3. å¿…éœ€æ¡ä»¶:
   - Vertex AI è®¤è¯æ–‡ä»¶: /mnt/nfs/chenlin/dataproc/vertex-ai.json
   - Python åŒ…: vertexai, Pillow
   - å®‰è£…å‘½ä»¤: pip install google-cloud-aiplatform pillow
        """)

